{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Nin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d32903795c77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuraccy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Nin' is not defined"
     ]
    }
   ],
   "source": [
    "x = layers.Input(shape=(Nin,))\n",
    "h = layers.Activation('relu')(layers.Dense(Nh)(x))\n",
    "y = layers.Activation('softmax')(layers.Dense(Nout)(h))\n",
    "model = models.Model(x,y)\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuraccy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-30-c8960b9984ab>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-30-c8960b9984ab>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class ANN(models.Model):\n",
    "    def __init__(self,Nin,Nh,Nout):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ANN'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-00694f664228>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mANN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mANN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ANN'"
     ]
    }
   ],
   "source": [
    "import ANN\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50,activation='relu',input_shape=(1,)))\n",
    "model.add(layers.Dense(50,activation='softmax'))\n",
    "model =ANN(1,1,Nout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import datasets\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test,y_test)= datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "L,W,H = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train =X_train.reshape(-1,W*H)\n",
    "X_test =X_test.reshape(-1,W*H)\n",
    "\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.0\n",
    "X_test= X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train','Test'],loc=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model acc')\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train','Test'],loc=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    Nin - 784\n",
    "    Nh = 100\n",
    "    number_of_class = 10\n",
    "    Nout = number_of_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "def ANN_models_fuc(Nin,Nh,Nout):\n",
    "    x = layers.Input(shape=(Nin,))\n",
    "    h = layers.Activation('relu')(layers.Dense(Nh)(x))\n",
    "    y = layers.Activation('softmax')(layers.Dense(Nout)(h))\n",
    "    model = models.Model(x,y)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuraccy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_seq_func(Nin,Nh,Nout):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Dense(Nh,activation='relu',input_dim=28*28))\n",
    "    model.add(layers.Dense(Nout,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='sgd',matrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN_seq_class(models.Sequential):\n",
    "    def __init__(self, Nin,Nh,Nout):\n",
    "        super().__init__()\n",
    "        self.add(layers.Dense(Nh,activation='relu',input_dim=28*28))\n",
    "        self.add(layers.Dense(Nout,activation='softmax'))\n",
    "        \n",
    "        self.compile(loss='categorical_crossentropy',optimizer='sgd',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.2       , 0.62352941, 0.99215686,\n",
       "       0.62352941, 0.19607843, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.18823529,\n",
       "       0.93333333, 0.98823529, 0.98823529, 0.98823529, 0.92941176,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.21176471, 0.89019608, 0.99215686, 0.98823529,\n",
       "       0.9372549 , 0.91372549, 0.98823529, 0.22352941, 0.02352941,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.03921569, 0.23529412, 0.87843137,\n",
       "       0.98823529, 0.99215686, 0.98823529, 0.79215686, 0.32941176,\n",
       "       0.98823529, 0.99215686, 0.47843137, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.63921569, 0.98823529, 0.98823529, 0.98823529, 0.99215686,\n",
       "       0.98823529, 0.98823529, 0.37647059, 0.74117647, 0.99215686,\n",
       "       0.65490196, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.2       , 0.93333333, 0.99215686,\n",
       "       0.99215686, 0.74509804, 0.44705882, 0.99215686, 0.89411765,\n",
       "       0.18431373, 0.30980392, 1.        , 0.65882353, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.18823529,\n",
       "       0.93333333, 0.98823529, 0.98823529, 0.70196078, 0.04705882,\n",
       "       0.29411765, 0.4745098 , 0.08235294, 0.        , 0.        ,\n",
       "       0.99215686, 0.95294118, 0.19607843, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.14901961, 0.64705882, 0.99215686, 0.91372549,\n",
       "       0.81568627, 0.32941176, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.99215686, 0.98823529,\n",
       "       0.64705882, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.02745098, 0.69803922,\n",
       "       0.98823529, 0.94117647, 0.27843137, 0.0745098 , 0.10980392,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.99215686, 0.98823529, 0.76470588, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.22352941, 0.98823529, 0.98823529, 0.24705882,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.99215686,\n",
       "       0.98823529, 0.76470588, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.77647059,\n",
       "       0.99215686, 0.74509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 1.        , 0.99215686, 0.76862745,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.29803922, 0.96470588, 0.98823529, 0.43921569,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.99215686, 0.98823529, 0.58039216, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.33333333,\n",
       "       0.98823529, 0.90196078, 0.09803922, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.02745098, 0.52941176, 0.99215686, 0.72941176,\n",
       "       0.04705882, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.33333333, 0.98823529, 0.8745098 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.02745098, 0.51372549,\n",
       "       0.98823529, 0.88235294, 0.27843137, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.33333333, 0.98823529, 0.56862745, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.18823529, 0.64705882, 0.98823529, 0.67843137, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.3372549 , 0.99215686,\n",
       "       0.88235294, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.44705882, 0.93333333, 0.99215686,\n",
       "       0.63529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.33333333, 0.98823529, 0.97647059, 0.57254902,\n",
       "       0.18823529, 0.11372549, 0.33333333, 0.69803922, 0.88235294,\n",
       "       0.99215686, 0.8745098 , 0.65490196, 0.21960784, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.33333333,\n",
       "       0.98823529, 0.98823529, 0.98823529, 0.89803922, 0.84313725,\n",
       "       0.98823529, 0.98823529, 0.98823529, 0.76862745, 0.50980392,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.10980392, 0.78039216, 0.98823529,\n",
       "       0.98823529, 0.99215686, 0.98823529, 0.98823529, 0.91372549,\n",
       "       0.56862745, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09803922, 0.50196078, 0.98823529, 0.99215686,\n",
       "       0.98823529, 0.55294118, 0.14509804, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nin = 784\n",
    "Nh = 50\n",
    "Nout = 10\n",
    "model = ANN_seq_class(Nin,Nh,Nout)\n",
    "(X_train, y_train),(X_test,y_test)= datasets.mnist.load_data()\n",
    "X_train[1]\n",
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# L,W,H = X_train.shape\n",
    "X_train =X_train.reshape(-1,W*H)\n",
    "X_test =X_test.reshape(-1,W*H)\n",
    "X_train = X_train/255.0\n",
    "X_test= X_test/255.0\n",
    "X_train[1]\n",
    "# X_train.shape\n",
    "# X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "48000/48000 [==============================] - 1s 14us/step - loss: 1.2777 - accuracy: 0.6694 - val_loss: 0.6936 - val_accuracy: 0.8432\n",
      "Epoch 2/15\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.5989 - accuracy: 0.8502 - val_loss: 0.4759 - val_accuracy: 0.8796\n",
      "Epoch 3/15\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.4679 - accuracy: 0.8767 - val_loss: 0.4017 - val_accuracy: 0.8946\n",
      "Epoch 4/15\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.4113 - accuracy: 0.8885 - val_loss: 0.3650 - val_accuracy: 0.9015\n",
      "Epoch 5/15\n",
      "48000/48000 [==============================] - 1s 14us/step - loss: 0.3788 - accuracy: 0.8954 - val_loss: 0.3432 - val_accuracy: 0.9053\n",
      "Epoch 6/15\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3567 - accuracy: 0.9008 - val_loss: 0.3262 - val_accuracy: 0.9105\n",
      "Epoch 7/15\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.3400 - accuracy: 0.9052 - val_loss: 0.3130 - val_accuracy: 0.9146\n",
      "Epoch 8/15\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.3269 - accuracy: 0.9079 - val_loss: 0.3027 - val_accuracy: 0.9158\n",
      "Epoch 9/15\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.3156 - accuracy: 0.9113 - val_loss: 0.2930 - val_accuracy: 0.9189\n",
      "Epoch 10/15\n",
      "48000/48000 [==============================] - 1s 12us/step - loss: 0.3057 - accuracy: 0.9140 - val_loss: 0.2851 - val_accuracy: 0.9208\n",
      "Epoch 11/15\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.2971 - accuracy: 0.9161 - val_loss: 0.2783 - val_accuracy: 0.9223\n",
      "Epoch 12/15\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.2892 - accuracy: 0.9180 - val_loss: 0.2719 - val_accuracy: 0.9246\n",
      "Epoch 13/15\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.2819 - accuracy: 0.9204 - val_loss: 0.2663 - val_accuracy: 0.9259\n",
      "Epoch 14/15\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.2751 - accuracy: 0.9225 - val_loss: 0.2607 - val_accuracy: 0.9271\n",
      "Epoch 15/15\n",
      "48000/48000 [==============================] - 1s 13us/step - loss: 0.2688 - accuracy: 0.9241 - val_loss: 0.2553 - val_accuracy: 0.9283\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train,epochs=15,batch_size=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 9us/step\n",
      "[0.25582334243692456, 0.9261999726295471]\n"
     ]
    }
   ],
   "source": [
    "perf = model.evaluate(X_test,Y_test,batch_size=100)\n",
    "print(perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)\n",
    "plot_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True : 9, Predict : [6.4007827e-04 2.1658009e-06 5.4198521e-04 3.4725745e-03 1.2561932e-03\n",
      " 1.3060834e-03 1.5996426e-04 5.5455964e-02 2.1525247e-03 9.3501240e-01]\n",
      "True : 5, Predict : [0.00053655 0.00262451 0.00122735 0.10988708 0.0033197  0.0377671\n",
      " 0.00663084 0.00084756 0.512791   0.3243684 ]\n",
      "True : 1, Predict : [1.6432348e-05 9.4575268e-01 9.0616215e-03 2.6345470e-03 1.8816287e-04\n",
      " 3.1654869e-04 7.7180396e-04 1.7968287e-03 3.8839538e-02 6.2181684e-04]\n",
      "True : 3, Predict : [3.2773550e-04 2.0215205e-06 1.8305585e-04 9.9140668e-01 4.1695832e-05\n",
      " 5.0768899e-03 9.7528516e-07 5.3744567e-05 2.4921428e-03 4.1508448e-04]\n",
      "True : 5, Predict : [5.4397568e-04 2.7526337e-06 4.0027272e-04 4.9453396e-03 1.2389818e-04\n",
      " 9.3880528e-01 2.0852053e-04 2.8521388e-06 5.4925509e-02 4.1665979e-05]\n"
     ]
    }
   ],
   "source": [
    "xhat_idx = np.random.choice(X_test.shape[0], 5)\n",
    "xhat = X_test[xhat_idx]\n",
    "yhat = model.predict_classes(xhat)\n",
    "\n",
    "for i in range(5):\n",
    "    print('True : ' + str(argmax(Y_test[xhat_idx[i]])) + ', Predict : ' + str(yhat[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True : 2, Predict : 5\n",
      "True : 2, Predict : 1\n",
      "True : 2, Predict : 7\n",
      "True : 3, Predict : 1\n",
      "True : 9, Predict : 4\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "xhat_idx = np.random.choice(x_test.shape[0], 5)\n",
    "xhat = x_test[xhat_idx]\n",
    "\n",
    "# # 2. 모델 불러오기\n",
    "# from keras.models import load_model\n",
    "# model = load_model('mnist_mlp_model.h5')\n",
    "\n",
    "# 3. 모델 사용하기\n",
    "yhat = model.predict_classes(xhat)\n",
    "\n",
    "for i in range(5):\n",
    "    print('True : ' + str(argmax(y_test[xhat_idx[i]])) + ', Predict : ' + str(yhat[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi =datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  51, 159, 253, 159,  50,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  48, 238, 252, 252, 252, 237,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         54, 227, 253, 252, 239, 233, 252,  57,   6,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,  60,\n",
       "        224, 252, 253, 252, 202,  84, 252, 253, 122,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 163, 252,\n",
       "        252, 252, 253, 252, 252,  96, 189, 253, 167,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 238, 253,\n",
       "        253, 190, 114, 253, 228,  47,  79, 255, 168,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238, 252, 252,\n",
       "        179,  12,  75, 121,  21,   0,   0, 253, 243,  50,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  38, 165, 253, 233, 208,\n",
       "         84,   0,   0,   0,   0,   0,   0, 253, 252, 165,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   7, 178, 252, 240,  71,  19,\n",
       "         28,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  57, 252, 252,  63,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 198, 253, 190,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 255, 253, 196,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  76, 246, 252, 112,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 253, 252, 148,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 230,  25,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   7, 135, 253, 186,  12,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 223,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   7, 131, 252, 225,  71,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 145,   0,   0,   0,   0,\n",
       "          0,   0,   0,  48, 165, 252, 173,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  86, 253, 225,   0,   0,   0,   0,\n",
       "          0,   0, 114, 238, 253, 162,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 249, 146,  48,  29,  85,\n",
       "        178, 225, 253, 223, 167,  56,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 252, 252, 229, 215, 252,\n",
       "        252, 252, 196, 130,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  28, 199, 252, 252, 253, 252, 252,\n",
       "        233, 145,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  25, 128, 252, 253, 252, 141,\n",
       "         37,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0. 사용할 패키지 불러오기\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "\n",
    "# 훈련셋과 시험셋 불러오기\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋 전처리\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18000 samples, validate on 42000 samples\n",
      "Epoch 1/5\n",
      "18000/18000 [==============================] - 1s 57us/step - loss: 1.1088 - accuracy: 0.7203 - val_loss: 0.6425 - val_accuracy: 0.8345\n",
      "Epoch 2/5\n",
      "18000/18000 [==============================] - 1s 54us/step - loss: 0.5121 - accuracy: 0.8669 - val_loss: 0.4756 - val_accuracy: 0.8689\n",
      "Epoch 3/5\n",
      "18000/18000 [==============================] - 1s 52us/step - loss: 0.4138 - accuracy: 0.8871 - val_loss: 0.4165 - val_accuracy: 0.8831\n",
      "Epoch 4/5\n",
      "18000/18000 [==============================] - 1s 52us/step - loss: 0.3696 - accuracy: 0.8974 - val_loss: 0.3816 - val_accuracy: 0.8923\n",
      "Epoch 5/5\n",
      "18000/18000 [==============================] - 1s 53us/step - loss: 0.3420 - accuracy: 0.9043 - val_loss: 0.3616 - val_accuracy: 0.8966\n",
      "10000/10000 [==============================] - 0s 10us/step\n",
      "\n",
      "loss_and_metrics : [0.33656349430680277, 0.9065999984741211]\n",
      "True : 3, Predict : 3\n",
      "True : 8, Predict : 8\n",
      "True : 3, Predict : 3\n",
      "True : 1, Predict : 1\n",
      "True : 3, Predict : 3\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "\n",
    "# 훈련셋과 시험셋 불러오기\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 데이터셋 전처리\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 원핫인코딩 (one-hot encoding) 처리\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "x_val = x_train[:42000] # 훈련셋의 30%를 검증셋으로 사용\n",
    "x_train = x_train[42000:]\n",
    "y_val = y_train[:42000] # 훈련셋의 30%를 검증셋으로 사용\n",
    "y_train = y_train[42000:]\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_val, y_val))\n",
    "\n",
    "# 5. 모델 평가하기\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)\n",
    "print('')\n",
    "print('loss_and_metrics : ' + str(loss_and_metrics))\n",
    "\n",
    "# 6. 모델 사용하기\n",
    "xhat_idx = np.random.choice(x_test.shape[0], 5)\n",
    "xhat = x_test[xhat_idx]\n",
    "yhat = model.predict_classes(xhat)\n",
    "\n",
    "for i in range(5):\n",
    "    print('True : ' + str(argmax(y_test[xhat_idx[i]])) + ', Predict : ' + str(yhat[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "Nin = 13\n",
    "Nh = 50\n",
    "Nout = 1\n",
    "model = models.Sequential()\n",
    "model.add(Dense(units=Nh, input_shape=(Nin,), activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(units=Nout)) \n",
    "model.compile(loss='mse', optimizer='sgd',metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.20322293e-04, 0.00000000e+00, 1.73387097e-01, 0.00000000e+00,\n",
       "       2.67489712e-01, 4.66111541e-01, 5.72605561e-01, 3.84376924e-01,\n",
       "       1.73913043e-01, 6.88336520e-02, 8.08510638e-01, 1.00000000e+00,\n",
       "       2.08609272e-01])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from keras import datasets\n",
    "(x_train, y_train), (x_test, y_test) = datasets.boston_housing.load_data()\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_train = scaler.fit_transform(x_train)\n",
    "X_test = scaler.transform(x_test)\n",
    "# mean = train_data.mean(axis=0)\n",
    "# train_data -= mean\n",
    "# std = train_data.std(axis=0)\n",
    "# train_data /= std\n",
    "# test_data -= mean\n",
    "# test_data /= std\n",
    "# Y_train = y_train/100\n",
    "# y_test = y_test/100\n",
    "y_train[1]\n",
    "X_train[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323 samples, validate on 81 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 386.4140 - mae: 16.5880 - val_loss: 623.8694 - val_mae: 23.2174\n",
      "Epoch 2/100\n",
      " - 0s - loss: 522.2021 - mae: 20.9254 - val_loss: 507.0344 - val_mae: 20.5524\n",
      "Epoch 3/100\n",
      " - 0s - loss: 375.8261 - mae: 16.9286 - val_loss: 112.1975 - val_mae: 8.7414\n",
      "Epoch 4/100\n",
      " - 0s - loss: 155.3794 - mae: 9.6601 - val_loss: 200.8786 - val_mae: 11.2226\n",
      "Epoch 5/100\n",
      " - 0s - loss: 89.6966 - mae: 6.7800 - val_loss: 66.5210 - val_mae: 6.4591\n",
      "Epoch 6/100\n",
      " - 0s - loss: 65.1566 - mae: 6.1842 - val_loss: 60.9898 - val_mae: 6.0170\n",
      "Epoch 7/100\n",
      " - 0s - loss: 65.9395 - mae: 5.8917 - val_loss: 132.0910 - val_mae: 10.6520\n",
      "Epoch 8/100\n",
      " - 0s - loss: 179.1154 - mae: 10.6851 - val_loss: 88.7678 - val_mae: 6.4235\n",
      "Epoch 9/100\n",
      " - 0s - loss: 76.9260 - mae: 6.1919 - val_loss: 67.0724 - val_mae: 5.1471\n",
      "Epoch 10/100\n",
      " - 0s - loss: 59.6352 - mae: 5.3006 - val_loss: 154.2769 - val_mae: 9.8310\n",
      "Epoch 11/100\n",
      " - 0s - loss: 113.0421 - mae: 8.3036 - val_loss: 65.2680 - val_mae: 5.9174\n",
      "Epoch 12/100\n",
      " - 0s - loss: 59.9292 - mae: 5.6260 - val_loss: 137.0347 - val_mae: 8.4980\n",
      "Epoch 13/100\n",
      " - 0s - loss: 80.3730 - mae: 6.0349 - val_loss: 56.0153 - val_mae: 5.8655\n",
      "Epoch 14/100\n",
      " - 0s - loss: 63.7470 - mae: 6.1210 - val_loss: 51.0332 - val_mae: 5.2814\n",
      "Epoch 15/100\n",
      " - 0s - loss: 53.3095 - mae: 5.3869 - val_loss: 71.7803 - val_mae: 6.9710\n",
      "Epoch 16/100\n",
      " - 0s - loss: 89.8562 - mae: 7.2355 - val_loss: 52.1304 - val_mae: 4.6947\n",
      "Epoch 17/100\n",
      " - 0s - loss: 42.6967 - mae: 4.3031 - val_loss: 66.5798 - val_mae: 5.3620\n",
      "Epoch 18/100\n",
      " - 0s - loss: 40.2998 - mae: 4.2748 - val_loss: 45.9184 - val_mae: 4.2866\n",
      "Epoch 19/100\n",
      " - 0s - loss: 35.1618 - mae: 3.9027 - val_loss: 101.6128 - val_mae: 7.3829\n",
      "Epoch 20/100\n",
      " - 0s - loss: 63.2421 - mae: 5.7445 - val_loss: 35.1525 - val_mae: 3.8907\n",
      "Epoch 21/100\n",
      " - 0s - loss: 31.0465 - mae: 3.5717 - val_loss: 35.2298 - val_mae: 3.7556\n",
      "Epoch 22/100\n",
      " - 0s - loss: 28.1879 - mae: 3.3260 - val_loss: 45.7065 - val_mae: 4.4545\n",
      "Epoch 23/100\n",
      " - 0s - loss: 92.9717 - mae: 7.4524 - val_loss: 80.0480 - val_mae: 5.9582\n",
      "Epoch 24/100\n",
      " - 0s - loss: 66.5877 - mae: 5.3048 - val_loss: 60.4766 - val_mae: 5.4014\n",
      "Epoch 25/100\n",
      " - 0s - loss: 68.0201 - mae: 6.0626 - val_loss: 87.6693 - val_mae: 8.0014\n",
      "Epoch 26/100\n",
      " - 0s - loss: 80.6872 - mae: 6.6429 - val_loss: 67.8782 - val_mae: 6.8159\n",
      "Epoch 27/100\n",
      " - 0s - loss: 70.0450 - mae: 6.3977 - val_loss: 59.6422 - val_mae: 5.5393\n",
      "Epoch 28/100\n",
      " - 0s - loss: 52.7007 - mae: 5.0185 - val_loss: 52.4143 - val_mae: 4.8813\n",
      "Epoch 29/100\n",
      " - 0s - loss: 44.6722 - mae: 4.5065 - val_loss: 50.8627 - val_mae: 5.4643\n",
      "Epoch 30/100\n",
      " - 0s - loss: 76.6664 - mae: 7.0695 - val_loss: 64.9545 - val_mae: 6.0656\n",
      "Epoch 31/100\n",
      " - 0s - loss: 57.2868 - mae: 5.2475 - val_loss: 53.7859 - val_mae: 4.7986\n",
      "Epoch 32/100\n",
      " - 0s - loss: 70.9804 - mae: 6.5377 - val_loss: 62.0325 - val_mae: 5.0810\n",
      "Epoch 33/100\n",
      " - 0s - loss: 48.8832 - mae: 4.6429 - val_loss: 61.7016 - val_mae: 6.5137\n",
      "Epoch 34/100\n",
      " - 0s - loss: 87.7843 - mae: 7.5775 - val_loss: 50.2568 - val_mae: 5.0803\n",
      "Epoch 35/100\n",
      " - 0s - loss: 48.0357 - mae: 4.8930 - val_loss: 47.8828 - val_mae: 4.5852\n",
      "Epoch 36/100\n",
      " - 0s - loss: 38.8729 - mae: 4.1068 - val_loss: 41.7636 - val_mae: 4.7818\n",
      "Epoch 37/100\n",
      " - 0s - loss: 60.8683 - mae: 5.9262 - val_loss: 90.5068 - val_mae: 8.6978\n",
      "Epoch 38/100\n",
      " - 0s - loss: 71.7592 - mae: 6.5620 - val_loss: 50.2426 - val_mae: 5.5175\n",
      "Epoch 39/100\n",
      " - 0s - loss: 48.7982 - mae: 5.2806 - val_loss: 51.1472 - val_mae: 5.6987\n",
      "Epoch 40/100\n",
      " - 0s - loss: 46.5300 - mae: 4.9653 - val_loss: 75.4886 - val_mae: 7.7820\n",
      "Epoch 41/100\n",
      " - 0s - loss: 74.3660 - mae: 7.0133 - val_loss: 42.9401 - val_mae: 4.6742\n",
      "Epoch 42/100\n",
      " - 0s - loss: 34.3958 - mae: 4.0229 - val_loss: 51.5850 - val_mae: 4.8874\n",
      "Epoch 43/100\n",
      " - 0s - loss: 56.6463 - mae: 5.5840 - val_loss: 72.6914 - val_mae: 6.4228\n",
      "Epoch 44/100\n",
      " - 0s - loss: 68.5888 - mae: 6.5255 - val_loss: 42.5955 - val_mae: 4.3031\n",
      "Epoch 45/100\n",
      " - 0s - loss: 35.1460 - mae: 3.8226 - val_loss: 30.1696 - val_mae: 4.0191\n",
      "Epoch 46/100\n",
      " - 0s - loss: 26.3533 - mae: 3.3444 - val_loss: 123.0008 - val_mae: 10.1932\n",
      "Epoch 47/100\n",
      " - 0s - loss: 142.9045 - mae: 10.0920 - val_loss: 58.5798 - val_mae: 6.0426\n",
      "Epoch 48/100\n",
      " - 0s - loss: 46.0912 - mae: 4.8256 - val_loss: 53.6848 - val_mae: 5.0215\n",
      "Epoch 49/100\n",
      " - 0s - loss: 42.6820 - mae: 4.4450 - val_loss: 34.4548 - val_mae: 4.1838\n",
      "Epoch 50/100\n",
      " - 0s - loss: 35.0723 - mae: 4.1042 - val_loss: 67.3983 - val_mae: 7.3038\n",
      "Epoch 51/100\n",
      " - 0s - loss: 73.2417 - mae: 7.2543 - val_loss: 43.5277 - val_mae: 5.1566\n",
      "Epoch 52/100\n",
      " - 0s - loss: 52.3205 - mae: 5.5509 - val_loss: 53.8809 - val_mae: 5.1296\n",
      "Epoch 53/100\n",
      " - 0s - loss: 45.7885 - mae: 4.8775 - val_loss: 49.7235 - val_mae: 5.9170\n",
      "Epoch 54/100\n",
      " - 0s - loss: 60.7167 - mae: 6.1348 - val_loss: 79.5851 - val_mae: 7.9840\n",
      "Epoch 55/100\n",
      " - 0s - loss: 55.2815 - mae: 5.5847 - val_loss: 29.5657 - val_mae: 3.6954\n",
      "Epoch 56/100\n",
      " - 0s - loss: 30.2802 - mae: 3.7261 - val_loss: 33.6539 - val_mae: 4.0653\n",
      "Epoch 57/100\n",
      " - 0s - loss: 30.7211 - mae: 3.8169 - val_loss: 133.2202 - val_mae: 9.0946\n",
      "Epoch 58/100\n",
      " - 0s - loss: 217.3765 - mae: 12.5160 - val_loss: 65.0937 - val_mae: 5.2160\n",
      "Epoch 59/100\n",
      " - 0s - loss: 52.9348 - mae: 4.8623 - val_loss: 55.7984 - val_mae: 5.2524\n",
      "Epoch 60/100\n",
      " - 0s - loss: 51.5487 - mae: 5.0550 - val_loss: 60.9115 - val_mae: 5.2329\n",
      "Epoch 61/100\n",
      " - 0s - loss: 49.9625 - mae: 4.7498 - val_loss: 50.1262 - val_mae: 4.7036\n",
      "Epoch 62/100\n",
      " - 0s - loss: 42.6755 - mae: 4.5404 - val_loss: 51.2447 - val_mae: 4.9063\n",
      "Epoch 63/100\n",
      " - 0s - loss: 92.1824 - mae: 7.8288 - val_loss: 82.0661 - val_mae: 5.8281\n",
      "Epoch 64/100\n",
      " - 0s - loss: 59.1628 - mae: 4.9713 - val_loss: 51.5375 - val_mae: 5.2662\n",
      "Epoch 65/100\n",
      " - 0s - loss: 45.5286 - mae: 4.8327 - val_loss: 68.5111 - val_mae: 7.1160\n",
      "Epoch 66/100\n",
      " - 0s - loss: 60.3208 - mae: 6.2052 - val_loss: 43.4862 - val_mae: 4.6190\n",
      "Epoch 67/100\n",
      " - 0s - loss: 40.4945 - mae: 4.4197 - val_loss: 37.1257 - val_mae: 4.1669\n",
      "Epoch 68/100\n",
      " - 0s - loss: 45.3922 - mae: 5.0692 - val_loss: 137.7811 - val_mae: 10.3079\n",
      "Epoch 69/100\n",
      " - 0s - loss: 100.3497 - mae: 7.9910 - val_loss: 44.5225 - val_mae: 4.6060\n",
      "Epoch 70/100\n",
      " - 0s - loss: 39.1683 - mae: 4.1835 - val_loss: 51.2731 - val_mae: 4.9687\n",
      "Epoch 71/100\n",
      " - 0s - loss: 50.1954 - mae: 5.3749 - val_loss: 170.8358 - val_mae: 11.2035\n",
      "Epoch 72/100\n",
      " - 0s - loss: 108.0887 - mae: 8.2584 - val_loss: 41.7939 - val_mae: 4.3532\n",
      "Epoch 73/100\n",
      " - 0s - loss: 36.0285 - mae: 4.0998 - val_loss: 33.9343 - val_mae: 4.1071\n",
      "Epoch 74/100\n",
      " - 0s - loss: 35.3523 - mae: 4.3155 - val_loss: 79.5253 - val_mae: 7.2793\n",
      "Epoch 75/100\n",
      " - 0s - loss: 75.5798 - mae: 7.1459 - val_loss: 38.5194 - val_mae: 4.3408\n",
      "Epoch 76/100\n",
      " - 0s - loss: 30.7698 - mae: 3.8163 - val_loss: 26.3001 - val_mae: 3.6865\n",
      "Epoch 77/100\n",
      " - 0s - loss: 39.3780 - mae: 4.4394 - val_loss: 251.3779 - val_mae: 14.0147\n",
      "Epoch 78/100\n",
      " - 0s - loss: 178.0577 - mae: 10.8287 - val_loss: 67.9911 - val_mae: 6.0302\n",
      "Epoch 79/100\n",
      " - 0s - loss: 56.7866 - mae: 5.3060 - val_loss: 59.5543 - val_mae: 5.5484\n",
      "Epoch 80/100\n",
      " - 0s - loss: 52.2754 - mae: 5.2548 - val_loss: 76.6804 - val_mae: 7.4430\n",
      "Epoch 81/100\n",
      " - 0s - loss: 58.3193 - mae: 6.1272 - val_loss: 38.1983 - val_mae: 4.5269\n",
      "Epoch 82/100\n",
      " - 0s - loss: 32.2070 - mae: 3.9349 - val_loss: 42.0363 - val_mae: 5.2303\n",
      "Epoch 83/100\n",
      " - 0s - loss: 75.2671 - mae: 7.0025 - val_loss: 60.4526 - val_mae: 6.3643\n",
      "Epoch 84/100\n",
      " - 0s - loss: 40.7073 - mae: 4.5501 - val_loss: 40.6460 - val_mae: 4.7178\n",
      "Epoch 85/100\n",
      " - 0s - loss: 32.8837 - mae: 4.2708 - val_loss: 26.1514 - val_mae: 3.6595\n",
      "Epoch 86/100\n",
      " - 0s - loss: 25.5586 - mae: 3.6607 - val_loss: 107.3640 - val_mae: 8.8316\n",
      "Epoch 87/100\n",
      " - 0s - loss: 87.9051 - mae: 8.0810 - val_loss: 34.4687 - val_mae: 4.2686\n",
      "Epoch 88/100\n",
      " - 0s - loss: 34.2920 - mae: 4.0989 - val_loss: 84.4335 - val_mae: 7.9215\n",
      "Epoch 89/100\n",
      " - 0s - loss: 81.4284 - mae: 7.4820 - val_loss: 33.0598 - val_mae: 3.9395\n",
      "Epoch 90/100\n",
      " - 0s - loss: 31.2333 - mae: 3.6900 - val_loss: 26.1352 - val_mae: 3.5973\n",
      "Epoch 91/100\n",
      " - 0s - loss: 22.7608 - mae: 3.1494 - val_loss: 23.7887 - val_mae: 3.4941\n",
      "Epoch 92/100\n",
      " - 0s - loss: 21.0293 - mae: 3.1360 - val_loss: 23.3365 - val_mae: 3.6503\n",
      "Epoch 93/100\n",
      " - 0s - loss: 52.6531 - mae: 5.6229 - val_loss: 162.1267 - val_mae: 10.9242\n",
      "Epoch 94/100\n",
      " - 0s - loss: 77.1643 - mae: 6.5005 - val_loss: 24.6305 - val_mae: 3.5161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      " - 0s - loss: 22.1886 - mae: 3.1650 - val_loss: 22.9794 - val_mae: 3.4945\n",
      "Epoch 96/100\n",
      " - 0s - loss: 48.4839 - mae: 5.1424 - val_loss: 38.3295 - val_mae: 5.1684\n",
      "Epoch 97/100\n",
      " - 0s - loss: 33.8932 - mae: 4.3473 - val_loss: 25.4297 - val_mae: 3.9168\n",
      "Epoch 98/100\n",
      " - 0s - loss: 34.0608 - mae: 4.5635 - val_loss: 42.2892 - val_mae: 5.4965\n",
      "Epoch 99/100\n",
      " - 0s - loss: 36.8565 - mae: 4.9306 - val_loss: 43.0180 - val_mae: 5.6849\n",
      "Epoch 100/100\n",
      " - 0s - loss: 34.9682 - mae: 4.8033 - val_loss: 34.8414 - val_mae: 4.6508\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=100, batch_size=100,\n",
    "                    validation_split=0.2,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.033775],\n",
       "       [22.23808 ],\n",
       "       [22.863352],\n",
       "       [36.386547],\n",
       "       [28.205673],\n",
       "       [22.25859 ],\n",
       "       [36.86302 ],\n",
       "       [27.485348],\n",
       "       [19.478516],\n",
       "       [23.589405],\n",
       "       [20.494366],\n",
       "       [21.325342],\n",
       "       [19.195532],\n",
       "       [37.21899 ],\n",
       "       [19.065079],\n",
       "       [23.090088],\n",
       "       [25.684658],\n",
       "       [24.89027 ],\n",
       "       [20.929592],\n",
       "       [35.304764],\n",
       "       [14.382618],\n",
       "       [14.184166],\n",
       "       [23.065067],\n",
       "       [19.67387 ],\n",
       "       [23.313736],\n",
       "       [29.2546  ],\n",
       "       [37.190685],\n",
       "       [30.540474],\n",
       "       [12.497822],\n",
       "       [23.37976 ],\n",
       "       [24.127747],\n",
       "       [14.512962],\n",
       "       [36.79756 ],\n",
       "       [23.713303],\n",
       "       [20.230034],\n",
       "       [13.698952],\n",
       "       [17.506126],\n",
       "       [22.582577],\n",
       "       [19.686146],\n",
       "       [33.45878 ],\n",
       "       [24.865532],\n",
       "       [34.137085],\n",
       "       [18.615055],\n",
       "       [37.121384],\n",
       "       [37.254898],\n",
       "       [23.473972],\n",
       "       [36.587357],\n",
       "       [20.989481],\n",
       "       [28.115768],\n",
       "       [23.77649 ],\n",
       "       [36.70992 ],\n",
       "       [21.239975],\n",
       "       [14.479299],\n",
       "       [18.9383  ],\n",
       "       [37.099003],\n",
       "       [32.445522],\n",
       "       [17.68539 ],\n",
       "       [37.254898],\n",
       "       [36.89213 ],\n",
       "       [25.735687],\n",
       "       [30.157784],\n",
       "       [19.69543 ],\n",
       "       [15.848096],\n",
       "       [22.631115],\n",
       "       [27.666714],\n",
       "       [26.841724],\n",
       "       [16.915016],\n",
       "       [32.323784],\n",
       "       [15.571211],\n",
       "       [14.021044],\n",
       "       [34.367554],\n",
       "       [31.08638 ],\n",
       "       [26.708614],\n",
       "       [15.69082 ],\n",
       "       [34.428947],\n",
       "       [22.996994],\n",
       "       [23.197376],\n",
       "       [24.402557],\n",
       "       [37.163868],\n",
       "       [13.77516 ],\n",
       "       [26.514214],\n",
       "       [37.254898],\n",
       "       [21.55926 ],\n",
       "       [18.218725],\n",
       "       [22.41703 ],\n",
       "       [21.401138],\n",
       "       [23.85493 ],\n",
       "       [23.818241],\n",
       "       [22.715504],\n",
       "       [36.103546],\n",
       "       [20.427097],\n",
       "       [22.752752],\n",
       "       [29.709106],\n",
       "       [36.55017 ],\n",
       "       [37.22558 ],\n",
       "       [21.919662],\n",
       "       [37.248734],\n",
       "       [37.201225],\n",
       "       [27.526081],\n",
       "       [36.60841 ],\n",
       "       [37.207897],\n",
       "       [25.082066]], dtype=float32)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 49us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[35.00195402257583, 4.711240291595459]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_mean_absolute_error'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-b5be8983d432>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartial_train_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartial_train_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mmae_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_mean_absolute_error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mall_mae_histories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmae_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_mean_absolute_error'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "k=4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "all_mae_histories = []\n",
    "for i in  range(k):\n",
    "    print(\"processing fold #\", i)\n",
    "    # 검증 데이터 분리\n",
    "    val_data  = train_data[i * num_val_samples: (i+1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i+1) * num_val_samples]\n",
    "\n",
    "    # 훈련 데이터 분리\n",
    "    partial_train_data = np.concatenate([train_data[:i*num_val_samples], train_data[(i + 1) * num_val_samples:]], axis=0)\n",
    "    partial_train_targets = np.concatenate([train_targets[:i*num_val_samples], train_targets[(i + 1) * num_val_samples:]], axis=0)\n",
    "\n",
    "    # 모델 학습\n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data, partial_train_targets, validation_data=(val_data, val_targets), epochs=num_epochs, batch_size=1, verbose=0)\n",
    "    \n",
    "    mae_history = history.history['val_mean_absolute_error']\n",
    "    all_mae_histories.append(mae_history)\n",
    "    \n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nin = 784\n",
    "Nh_l = [100,50]\n",
    "number_of_class = 10\n",
    "NOut = number_of_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(models.Sequential):\n",
    "    def __init__(self,Nin,Nh_l,Nout):\n",
    "        super().__init__()\n",
    "        self.add(layers.Dense(Nh_l[0],activation='relu',\n",
    "                 input_shape=(Nin,),name='Hidden-1'))\n",
    "        self.add(layers.Dropout(0.2))\n",
    "        self.add(layers.Dense(Nh_l[1],activation='relu',name='Hidden-2'))\n",
    "        self.add(layers.Dropout(0.2))\n",
    "        self.add(layers.Dense(NOut, activation='softmax'))\n",
    "        self.compile(loss='categorical_crossentropy',optimizer='adam')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import datasets\n",
    "from keras.utils import np_utils\n",
    "\n",
    "(X_train, y_train),(X_test,y_test)= datasets.mnist.load_data()\n",
    "X_train[1]\n",
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_test = np_utils.to_categorical(y_test)\n",
    "L,W,H = X_train.shape\n",
    "X_train = X_train.reshape(-1,W*H)\n",
    "X_test = X_test.reshape(-1,W*H)\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.5166 - val_loss: 0.1823\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.2311 - val_loss: 0.1393\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1800 - val_loss: 0.1192\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1452 - val_loss: 0.1022\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.1302 - val_loss: 0.0990\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1150 - val_loss: 0.0887\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.1022 - val_loss: 0.0863\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0937 - val_loss: 0.0835\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0848 - val_loss: 0.0928\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0804 - val_loss: 0.0863\n"
     ]
    }
   ],
   "source": [
    "model= DNN(Nin,Nh_l,Nout)\n",
    "history = model.fit(X_train,Y_train, epochs=10, batch_size=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 9us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07849675426725299"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_test = model.evaluate(X_test,Y_test,batch_size=100)\n",
    "perf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import datasets\n",
    "from keras.utils import np_utils\n",
    "(X_train, y_train),(X_test,y_test)= datasets.cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "L,W,H,K = X_train.shape\n",
    "X_train = X_train.reshape(-1,W*H*K)\n",
    "X_test = X_test.reshape(-1,W*H*K)\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, LSTM, Dropout\n",
    "Nin = 3072\n",
    "Nh_l = [100,50]\n",
    "Pd_l = [0.0,0.0]\n",
    "number_of_class = 10\n",
    "Nout = number_of_class\n",
    "\n",
    "model = models.Sequential()  \n",
    "model.add(layers.Dense(Nh_l[0],activation='relu',input_dim=Nin))\n",
    "model.add(Dropout(Pd_l[0]))\n",
    "model.add(layers.Dense(Nh_l[1],activation='relu'))\n",
    "model.add(Dropout(Pd_l[1]))\n",
    "model.add(layers.Dense(Nout,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ann_mnist_cl import plot_loss, plot_acc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 3072), (50000, 10))"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 1.9243 - accuracy: 0.3049 - val_loss: 1.7974 - val_accuracy: 0.3660\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 1.7505 - accuracy: 0.3745 - val_loss: 1.7322 - val_accuracy: 0.3784\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 1.6856 - accuracy: 0.3980 - val_loss: 1.7005 - val_accuracy: 0.3970\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 1.6352 - accuracy: 0.4176 - val_loss: 1.6388 - val_accuracy: 0.4201\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 1.5982 - accuracy: 0.4313 - val_loss: 1.6132 - val_accuracy: 0.4350\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 1.5729 - accuracy: 0.4405 - val_loss: 1.6308 - val_accuracy: 0.4242\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 1.5582 - accuracy: 0.4451 - val_loss: 1.5963 - val_accuracy: 0.4374\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 1.5328 - accuracy: 0.4520 - val_loss: 1.5662 - val_accuracy: 0.4435\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 1.5112 - accuracy: 0.4607 - val_loss: 1.5858 - val_accuracy: 0.4391\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 3s 71us/step - loss: 1.4963 - accuracy: 0.4662 - val_loss: 1.5732 - val_accuracy: 0.4376\n",
      "10000/10000 [==============================] - 0s 27us/step\n",
      "[1.5407756662368775, 0.44850000739097595]\n",
      "True : 7, Predict : 7\n",
      "True : 5, Predict : 7\n",
      "True : 7, Predict : 7\n",
      "True : 4, Predict : 2\n",
      "True : 3, Predict : 3\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=10, batch_size=100, validation_split=0.2)\n",
    "perf_test = model.evaluate(X_test,Y_test,batch_size=100)\n",
    "print(perf_test)\n",
    "xhat_idx = np.random.choice(X_test.shape[0], 5)\n",
    "xhat = X_test[xhat_idx]\n",
    "yhat = model.predict_classes(xhat)\n",
    "\n",
    "for i in range(5):\n",
    "    print('True : ' + str(argmax(Y_test[xhat_idx[i]])) + ', Predict : ' + str(yhat[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras import models, layers\n",
    "from keras import backend\n",
    "from keras import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "(x_train, y_train),(x_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "img_rows, img_cols = x_train.shape[1:]\n",
    "if backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0],1,img_rows,img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0],1,img_rows,img_cols)\n",
    "    input_shape =(1,img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0],img_rows,img_cols,1)\n",
    "    x_test = x_test.reshape(x_test.shape[0],img_rows,img_cols,1)\n",
    "    input_shape =(img_rows, img_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /=255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = input_shape\n",
    "model = models.Sequential()  \n",
    "model.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu',input_shape= input_shape))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(num_classes,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 83s 2ms/step - loss: 0.2323 - accuracy: 0.9294 - val_loss: 0.0561 - val_accuracy: 0.9840\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 82s 2ms/step - loss: 0.0818 - accuracy: 0.9758 - val_loss: 0.0565 - val_accuracy: 0.9832\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 82s 2ms/step - loss: 0.0600 - accuracy: 0.9815 - val_loss: 0.0432 - val_accuracy: 0.9866\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 82s 2ms/step - loss: 0.0465 - accuracy: 0.9856 - val_loss: 0.0417 - val_accuracy: 0.9884\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 82s 2ms/step - loss: 0.0372 - accuracy: 0.9883 - val_loss: 0.0438 - val_accuracy: 0.9879\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 82s 2ms/step - loss: 0.0308 - accuracy: 0.9903 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 82s 2ms/step - loss: 0.0280 - accuracy: 0.9910 - val_loss: 0.0456 - val_accuracy: 0.9878\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 82s 2ms/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 0.0481 - val_accuracy: 0.9888\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 82s 2ms/step - loss: 0.0214 - accuracy: 0.9930 - val_loss: 0.0492 - val_accuracy: 0.9883\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 82s 2ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.0485 - val_accuracy: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x127c2908>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=128,epochs=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 286us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04190211260231126, 0.989799976348877]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True : 4, Predict : 4\n",
      "True : 7, Predict : 7\n",
      "True : 1, Predict : 1\n",
      "True : 9, Predict : 9\n",
      "True : 1, Predict : 1\n",
      "True : 1, Predict : 1\n",
      "True : 2, Predict : 2\n",
      "True : 7, Predict : 7\n",
      "True : 8, Predict : 8\n",
      "True : 9, Predict : 9\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "\n",
    "xhat_idx = np.random.choice(x_test.shape[0], 10)\n",
    "xhat = x_test[xhat_idx]\n",
    "yhat = model.predict_classes(xhat)\n",
    "\n",
    "for i in range(10):\n",
    "    print('True : ' + str(argmax(y_test[xhat_idx[i]])) + ', Predict : ' + str(yhat[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "assert keras.backend.image_data_format() == 'channels_last'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,y),(x_test,y_tset)=datasets.cifar10.load_data()\n",
    "nb_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_shape = \n",
    "model = models.Sequential()  \n",
    "model.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu',input_shape= in_shape))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D((pool_size=(2,2))))\n",
    "\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(nb_classes,activation='softmax',name='preds'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train,y_test = model_selection.train_test_split(X,y,test_size=0.2,random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 32, 32, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(X_train.shape[0],-1)).reshape(X_train.shape)\n",
    "X_test = scaler.fit_transform(X_test.reshape(X_test.shape[0],-1)).reshape(X_test.shape)\n",
    "X_train.shape, X_test.shape\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_chnnels(self):\n",
    "    x = self.x\n",
    "    if len(X.shape)==3:\n",
    "        N,img_rows,img_cols = X.shape\n",
    "        if K.image_dim_ordering() =='th':\n",
    "            X = X.reshape(X.shape[0],img_rows,img_cols)\n",
    "            input_shape = (1,img_rows,img_cols)\n",
    "        else:\n",
    "            X = X.reshape(X.shape[0],img_rows,img_cols)\n",
    "            input_shape = (img_rows,img_cols,1)\n",
    "    else:\n",
    "        input_shape = X.shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras import layers, models\n",
    "import numpy as np\n",
    "from numpy import argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test,y_test) = imdb.load_data(num_words=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train,maxlen=80)\n",
    "X_test = sequence.pad_sequences(X_test,maxlen=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= models.Sequential()\n",
    "model.add(layers.Embedding(20000,128,input_length=80))\n",
    "model.add(layers.LSTM(128,dropout=0.2,recurrent_dropout=0.2))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(20000, 128, input_length=200))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(256,\n",
    "                 3,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 74s 3ms/step - loss: 0.6935 - accuracy: 0.4993 - val_loss: 0.6941 - val_accuracy: 0.5076\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 75s 3ms/step - loss: 0.6794 - accuracy: 0.5671 - val_loss: 0.7137 - val_accuracy: 0.4974\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 75s 3ms/step - loss: 0.5993 - accuracy: 0.6707 - val_loss: 0.8394 - val_accuracy: 0.4962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14a63d48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32,epochs=3,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 10s 404us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8393787282943725, 0.49619999527931213)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test, y_test,batch_size = 32)\n",
    "score, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5813714 ],\n",
       "       [0.3278185 ],\n",
       "       [0.3108588 ],\n",
       "       ...,\n",
       "       [0.3943168 ],\n",
       "       [0.5871031 ],\n",
       "       [0.35366386]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from keras import models, layers\n",
    "from keras.datasets import mnist\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test,y_test) = mnist.load_data()\n",
    "X_train = X_train.astype('float32')/255.\n",
    "X_test = X_test.astype('float32')/255.\n",
    "X_train = X_train.reshape(len(X_train), np.prod(X_train.shape[1:]))\n",
    "X_test = X_test.reshape(len(X_test), np.prod(X_test.shape[1:]))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder =autoencoder.Encoder()\n",
    "decoder =autoencoder.Decoder()\n",
    "\n",
    "encoded_imgs = encoder.predict(X_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(models.Dense(36, activation='relu',input_shape=(784)))\n",
    "model.add(models.Dense(784,acivation='sigmoid'))\n",
    "model.compile(optimizer='adadelta',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "def Decoder():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
